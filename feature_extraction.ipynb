{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'love': 3, 'nlp': 4, 'is': 1, 'amazing': 0, 'learning': 2}\n",
      "Bag of words represemntation:\n",
      " [[0 0 0 1 1]\n",
      " [1 1 0 0 1]\n",
      " [0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Bag of words (BoW)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"I love NLP\",\n",
    "    \"NLP is amazing\",\n",
    "    \"I love learning NLP\"\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"Vocabulary:\", vectorizer.vocabulary_)\n",
    "print(\"Bag of words represemntation:\\n\", X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'nlp': 9, 'is': 5, 'amazng': 0, 'and': 1, 'exciting': 2, 'love': 7, 'studying': 13, 'working': 14, 'on': 10, 'projects': 12, 'machine': 8, 'learning': 6, 'includes': 4, 'other': 11, 'fields': 3}\n",
      "TF-IDF Matrix\n",
      " [[0.52004008 0.30714405 0.52004008 0.         0.         0.52004008\n",
      "  0.         0.         0.         0.30714405 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.22742704 0.         0.         0.         0.\n",
      "  0.         0.38506745 0.         0.45485408 0.38506745 0.\n",
      "  0.38506745 0.38506745 0.38506745]\n",
      " [0.         0.24743277 0.         0.4189401  0.4189401  0.\n",
      "  0.4189401  0.         0.4189401  0.24743277 0.         0.4189401\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF using scikit learn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_corpus = [\n",
    "    \"NLP is amazng and exciting\",\n",
    "    \"I love studying NLP and working on NLP projects\",\n",
    "    \"Machine learning includes NLP and other fields\"\n",
    "]\n",
    "\n",
    "vectorizer =  TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(tf_corpus)\n",
    "\n",
    "print(\"Vocabulary:\", vectorizer.vocabulary_)\n",
    "\n",
    "# Display he TF_IDF matrix in array format\n",
    "print(\"TF-IDF Matrix\\n\", tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Word Embeddings - Word2Vec (requires gensim)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mword2vec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Text8Corpus\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Workspace/NLP/Exercises/env/lib/python3.12/site-packages/gensim/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m4.3.3\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m     14\u001b[39m logger = logging.getLogger(\u001b[33m'\u001b[39m\u001b[33mgensim\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger.handlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Workspace/NLP/Exercises/env/lib/python3.12/site-packages/gensim/corpora/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexedcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmmcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbleicorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Workspace/NLP/Exercises/env/lib/python3.12/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[32m     16\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIndexedCorpus\u001b[39;00m(interfaces.CorpusABC):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Workspace/NLP/Exercises/env/lib/python3.12/site-packages/gensim/interfaces.py:19\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[33;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[32m     22\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCorpusABC\u001b[39;00m(utils.SaveLoad):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Workspace/NLP/Exercises/env/lib/python3.12/site-packages/gensim/matutils.py:1034\u001b[39m\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1.\u001b[39m - \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 & set2)) / \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1033\u001b[39m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_matutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlogsumexp\u001b[39m(x):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Workspace/NLP/Exercises/env/lib/python3.12/site-packages/gensim/_matutils.pyx:1\u001b[39m, in \u001b[36minit gensim._matutils\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# Word Embeddings - Word2Vec (requires gensim)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    [\"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n",
    "    [\"dog\", \"barked\", \"at\", \"the\", \"cat\"],\n",
    "    [\"the\", \"dog\", \"sat\", \"on\", \"the\", \"mat\"],\n",
    "    [\"cats\", \"and\", \"dogs\", \"are\", \"friends\"],\n",
    "    [\"dogs\", \"chase\", \"cats\"]\n",
    "]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "\n",
    "model = Word2Vec(sentences=corpus, vector_size=50, window=2, min_count=1, sg=1)\n",
    "\n",
    "print(\"Vocabulary:\", list(model.wv.index_to_key))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
